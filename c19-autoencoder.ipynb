{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This script uses a training set of x-rays for C19 negative patients. The images are used to train up an autoencoder which attempts to encode and then reconstruct the input. The aim is to present it with a test set comprising a mixture of C19 positive and negative images. If the trained autoencoder generally has a higher reconstruction error on the C19 positive images, it will be essentially flagging these as anomalous and differentiating them from the negative images.\n",
    "\n",
    "A visual representation of an autoencoder is seen here. It is simply trained to reconstruct it's source. So, if an image is fed into the trained autoencoder and is reconstructed poorly, we know this image is different in nature to a typical training set images. So, we hope to train the autoencoder on covid-19 negative images in the hope it will flag covid-19 positive images as anomalies:\n",
    "\n",
    "![title](autoencoder_image.png)\n",
    "\n",
    "For each new image fed into the trained autoencoder, the end output is the Mean Squared Error (MSE) between the original image and the reconstructed one. Hopefully images with a MSE above a given threshold will tend to be covid-positive. Ideally this would be enough to infer a diagnosis, but realistically this method will form part of a wider methodology. The MSE of the image could be used as an input for a classifier, for example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries and defining global variables\n",
    "\n",
    "NOTE THE ABSOLUTE FILEPATH HERE - THIS NEEDS CHANGING TO WHERE THE DATASET RESIDES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\ahall\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ahall\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ahall\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ahall\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ahall\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ahall\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D,Flatten,Reshape,LeakyReLU\n",
    "from keras.models import Model\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "BATCH_SIZE=16\n",
    "LEARNING_RATE=0.0001\n",
    "NUM_EPOCHS=20\n",
    "MAIN_ACTIVATION_FN = LeakyReLU()\n",
    "X_SIZE=256#236#124\n",
    "Y_SIZE=256#188#92\n",
    "SRC_DIR=\"C:\\\\Users\\\\ahall\\\\Documents\\\\datasets\\\\covid19-radiography-database\\\\COVID-19 Radiography Database\"\n",
    "TRAIN_NEW_MODEL = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an input stream\n",
    "This function uses the keras data generator method to build a stream of input images from a folder of raw images. Additional preprocessing may be added at a later stage.\n",
    "\n",
    "It will probably be necessary to test with a 'test positive' and 'test_negative' set so we can see whether the autoencoder differentiates between positive and negative x-rays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2473 images belonging to 1 classes.\n",
      "Found 219 images belonging to 1 classes.\n",
      "Found 213 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "def build_data_generator(phase,x_size,y_size,batch_size,shf):\n",
    "    datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "    data_generator = datagen.flow_from_directory(\n",
    "    directory=os.path.join(SRC_DIR,phase),\n",
    "    target_size=(y_size, x_size),\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"input\",\n",
    "    shuffle=shf,\n",
    "    seed=42)\n",
    "    \n",
    "    return data_generator\n",
    "\n",
    "train_generator = build_data_generator(\"train_negative\",X_SIZE,Y_SIZE,BATCH_SIZE,True)\n",
    "test_positive_generator = build_data_generator(\"test_positive\",X_SIZE,Y_SIZE,1,False)\n",
    "test_negative_generator = build_data_generator(\"test_negative\",X_SIZE,Y_SIZE,1,False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the autoencoder\n",
    "Here the architecture of the autoencoder is defined. We start with the input image and through repeated convolutional layers and pooling layers, we transform it into a one-dimensional vector. This is fed into a number of fully connected hidden layers before being reconstructed into the 'decoded' image at the end. A perfect autoencoder would take the input and be able to reconstruct it with 100% accuracy. Ours will be trained to reconstruct covid-negative images. So, if covid-positive images have unique features that can be sufficiently distinguished, it will not be ableto reconstruct them as accurately as the negative images.\n",
    "\n",
    "Note, the architecture here is quite aggressive - it compresses the input into a vector before reconstructing it. This should help prevent overfitting but also make the network susceptible to missing finer details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ahall\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "input_img = Input(shape=(Y_SIZE, X_SIZE, 1))\n",
    "\n",
    "x = Conv2D(2, (2, 2), padding='same')(input_img)\n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "x = Conv2D(4, (2, 2), padding='same')(input_img)\n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (2, 2), padding='same')(x)\n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "x = Conv2D(16, (2, 2),  padding='same')(x)\n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (2, 2),  padding='same')(x)\n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "x= MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(64, (2, 2), padding='same')(x)\n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "x= MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(128, (2, 2), padding='same')(x)\n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "x= MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(256, (2, 2),  padding='same')(x)\n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "#x = Conv2D(256, (2, 2), activation='relu', padding='same')(x)\n",
    "x= MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(512, (2, 2),  padding='same')(x)\n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "#x = Conv2D(512, (2, 2), activation='relu', padding='same')(x)\n",
    "x= MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(2048, (2, 2),  padding='same')(x)\n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "#x = Conv2D(2048, (2, 2), activation='relu', padding='same')(x)\n",
    "\n",
    "encoded = MaxPooling2D((2, 2))(x) \n",
    "encoded = Flatten()(encoded)\n",
    "\n",
    "#the representation is now 1x1x2048\n",
    "\n",
    "#fully connected layer\n",
    "x=Dense(2048)(encoded)\n",
    "x=Reshape((1,1,2048))(x)\n",
    "\n",
    "\n",
    "\n",
    "x = Conv2D(2048, (2, 2), padding='same')(x)\n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "#x = Conv2D(2048, (2, 2), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(512, (2, 2),  padding='same')(x)\n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "#x = Conv2D(512, (2, 2), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(256, (2, 2),  padding='same')(x)\n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "#x = Conv2D(256, (2, 2), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(128, (2, 2),  padding='same')(x)\n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (2, 2),  padding='same')(x) \n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (2, 2),  padding='same')(x)\n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "x = Conv2D(16, (2, 2),  padding='same')(x)\n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (2, 2),  padding='same')(x)\n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "x = Conv2D(4, (2, 2),  padding='same')(x)\n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(2, (2, 2), padding='same')(x)\n",
    "x=MAIN_ACTIVATION_FN(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (2, 2), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "opt =keras.optimizers.Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "#opt=keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "#opt=keras.optimizers.SGD(lr=LEARNING_RATE, momentum=0.0, decay=0.05, nesterov=False)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "encoder = Model(input_img,encoded)\n",
    "autoencoder.compile(optimizer=opt, loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the autoencoder\n",
    "Here we introduce the training set of covid negative images to the autoencoder network. The training process should create a network able to reconstruct its input with reasonable accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_NEGATIVE_TEST=test_negative_generator.n//test_negative_generator.batch_size\n",
    "STEP_SIZE_POSITIVE_TEST=test_positive_generator.n//test_positive_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ahall\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "if(TRAIN_NEW_MODEL):\n",
    "    autoencoder.fit_generator(generator=train_generator,\n",
    "                        steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                        validation_data=test_negative_generator,\n",
    "                        validation_steps=STEP_SIZE_NEGATIVE_TEST,\n",
    "                        epochs=NUM_EPOCHS,\n",
    "                        callbacks=[TensorBoard(log_dir='./tensorboard_logs')]\n",
    "    )\n",
    "\n",
    "    autoencoder.save (\"flattening_autoencoder.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the autoencoder\n",
    "Here we allow the autoencoder to encode and reconstruct test set images. We feed a test set of covid positive images and measure the RMSE between the input and reconstructed images. We hope to see a higher MSE for the covid positive images.\n",
    "\n",
    "The current method of iterating over the predictions and calculating MSE is not particularly efficient, it was necessitated by the fact that the prediction method introduces extra dimensions to the result. This section could therefor ebe cleaned up if we get the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = keras.models.load_model('flattening_autoencoder.h5')\n",
    "positive_predictions = autoencoder.predict_generator(generator=test_positive_generator, steps=STEP_SIZE_POSITIVE_TEST)\n",
    "negative_predictions = autoencoder.predict_generator(generator=test_negative_generator, steps=STEP_SIZE_NEGATIVE_TEST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "positive_mse_list = []\n",
    "negative_mse_list = []\n",
    "\n",
    "#refactor these later\n",
    "for i in range(len(test_positive_generator)):\n",
    "    p_mse = (np.square(test_positive_generator[i][0][0] - positive_predictions[i])).mean(axis=None)\n",
    "    positive_mse_list.append(p_mse)\n",
    "\n",
    "for i in range(len(test_negative_generator)):\n",
    "    n_mse = (np.square(test_negative_generator[i][0][0] - negative_predictions[i])).mean(axis=None)\n",
    "    negative_mse_list.append(n_mse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the results\n",
    "These plots do seem to show some distinction between the positive and negative cases, however it is far too early to draw conclusions. For this trial dataset, there were twice as many positive test cases so we may be seeing the effect of more outliers. Further statistical validation will be necessary, with a far larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig=plt.figure(figsize=(9, 4), dpi= 80, facecolor='w', edgecolor='k')\n",
    "pos=plt.scatter(positive_mse_list, np.ones_like(positive_mse_list), c='b')\n",
    "neg=plt.scatter(negative_mse_list, np.zeros_like(negative_mse_list), c='r')\n",
    "plt.legend((pos,neg),(\"positive_cases (total = \" + str(len(positive_mse_list)) +\")\",\"negative_cases (total = \"  + str(len(negative_mse_list)) +\")\"))\n",
    "plt.title(\"MSE of positive and negative test cases\")\n",
    "plt.xlabel(\"MSE\")\n",
    "plt.yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, a density plot does seem to show a difference in MSE between positive and negative cases, but more work will be necessary to determine if this is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "f, ax = plt.subplots(figsize=(10,6))\n",
    "ax = sn.kdeplot(positive_mse_list, label=\"positive_cases\", color='b', legend = True)\n",
    "ax = sn.kdeplot(negative_mse_list, label=\"negative_cases\", color='r', legend = True).set_title(\"kernal density plot for MSE of negative and positive cases\")\n",
    "plt.xlabel(\"MSE\")\n",
    "plt.ylabel(\"KDE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting some example images\n",
    "Here we plot raw images, and then the reconstructed images after they have been fed through the autoencoder. This allows us to visually see how the autoencoder attempts to reeconstruct the images. It seems to do a reasonable job for now (although that doesn't necessarily matter - what matters is that is systematically reconstructs C19 positive and negative images differently)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "\n",
    "def plot_examples(originals, predictions, title, mse_list):\n",
    "    fig=plt.figure(figsize=(15, 15), dpi= 80)\n",
    "    fig.suptitle(title)\n",
    "    for i in range(5):\n",
    "        example = random.randint(0,len(predictions)-1)\n",
    "\n",
    "        ax = plt.subplot(5, 2, (2*i)+1)\n",
    "        plt.imshow(np.squeeze(originals[example][0][0]))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        ax.set_title(\"Original\" , fontsize=10)\n",
    "\n",
    "        #display encoded image\n",
    "        ax = plt.subplot(5, 2, 2*i +2)\n",
    "        plt_img = predictions[example]\n",
    "        grey=np.squeeze(predictions[example]*255)\n",
    "        plt.imshow(grey)\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        ax.set_title(\"Reconstructed - MSE =\" + str(mse_list[example]), fontsize=10)\n",
    "        i=i+1\n",
    "        \n",
    "plot_examples(test_negative_generator, negative_predictions, \"covid negative scans - original and reconstructed\", negative_mse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_examples(test_positive_generator, positive_predictions, \"covid positive scans - original and reconstructed\", positive_mse_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
